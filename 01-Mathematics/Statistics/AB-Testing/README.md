# A/B Testing

Design and analysis of experiments to compare two versions of a product.

## ðŸŽ¯ Key Topics

### 1. The Experiment
Split users into two groups: Group A (Control) gets the current version, and Group B (Variant) gets a new feature. We measure a specific metric (e.g., Click-Through Rate) to see if Group B performs better.

### 2. Power Analysis
Determining the **Sample Size** needed to detect a meaningful difference. If the sample size is too small, we might miss a real improvement (High Type II error).

### 3. Pitfalls
- **Peeking**: Checking results too early and stopping the test.
- **Selection Bias**: If Group A and B are not truly random.
- **Novelty Effect**: Users might click more just because something is new, not because it is better.

## ðŸ“š Why it Matters
A/B testing is how companies like Netflix, Google, and Amazon make decisions. It is the practical application of hypothesis testing in a business context.
