# Optimization

Optimization is the process of finding the best parameters for a model to minimize the error (loss) on a given dataset.

## ðŸŽ¯ Core Concepts
- **Gradient Descent**: The workhorse of ML optimization.
- **Learning Rate Schedules**: Controlling step size.
- **Loss Surfaces**: Geometric interpretation of the objective function.
- **Convexity**: Understanding global vs local minima.

## ðŸ“‚ Subfolders
- [Gradient Descent](./Gradient-Descent)
- [Learning Rate Schedules](./Learning-Rate-Schedules)
- [Loss Surfaces](./Loss-Surfaces)
- [Convex vs Non-Convex](./Convex-vs-Non-Convex)
